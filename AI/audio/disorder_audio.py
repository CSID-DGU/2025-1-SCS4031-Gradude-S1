import os
import torch
import torchaudio
import numpy as np
import joblib
import logging
from transformers import WhisperProcessor, WhisperModel

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# âœ… ê¸€ë¡œë²Œ ìºì‹± ë³€ìˆ˜
_cached_scaler = None
_cached_classifier = None
_cached_processor = None
_cached_whisper_model = None
_cached_device = None

# âœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ)
def load_model(model_path="svm_model.pkl"):
    global _cached_scaler, _cached_classifier

    if _cached_scaler is not None and _cached_classifier is not None:
        return _cached_scaler, _cached_classifier

    try:
        saved_objects = joblib.load(model_path)
        _cached_scaler = saved_objects["scaler"]
        _cached_classifier = saved_objects["classifier"]
        logging.info("ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        return _cached_scaler, _cached_classifier
    except Exception as e:
        logging.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

# âœ… Whisper ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ)
def load_whisper_model():
    global _cached_processor, _cached_whisper_model, _cached_device

    if _cached_processor is not None and _cached_whisper_model is not None:
        return _cached_processor, _cached_whisper_model, _cached_device

    try:
        _cached_device = torch.device("cpu")
        _cached_processor = WhisperProcessor.from_pretrained("openai/whisper-base")
        _cached_whisper_model = WhisperModel.from_pretrained("openai/whisper-base").to(_cached_device).eval()
        logging.info("Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return _cached_processor, _cached_whisper_model, _cached_device
    except Exception as e:
        logging.error(f"Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

# âœ… PCM/WAV íŒŒì¼ ë¡œë”©
def load_audio(path, sr=16000, dtype=np.int16):
    if not os.path.exists(path):
        logging.error(f"íŒŒì¼ ê²½ë¡œ ì—†ìŒ: {path}")
        raise FileNotFoundError(f"íŒŒì¼ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

    try:
        if path.endswith(".wav"):
            waveform, sr = torchaudio.load(path)
        elif path.endswith(".pcm"):
            with open(path, 'rb') as f:
                pcm = np.frombuffer(f.read(), dtype=dtype)
                waveform = pcm.astype(np.float32) / 32768.0
                waveform = torch.from_numpy(waveform).unsqueeze(0)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í¬ë§·: {path}")

        if sr != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
            waveform = resampler(waveform)

        if waveform.shape[0] > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)

        return waveform.squeeze()

    except Exception as e:
        logging.error(f"ì˜¤ë””ì˜¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

# âœ… Whisper ì„ë² ë”© ì¶”ì¶œ
def extract_embedding(path, processor, model, device):
    waveform = load_audio(path)
    try:
        inputs = processor(waveform.numpy(), sampling_rate=16000, return_tensors="pt").to(device)

        with torch.no_grad():
            outputs = model(**inputs, decoder_input_ids=torch.tensor([[1]]))
            embedding = outputs.encoder_last_hidden_state.mean(dim=1).squeeze().cpu()
        return embedding.numpy()
    except Exception as e:
        logging.error(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        raise

# âœ… ì˜ˆì¸¡ ìˆ˜í–‰ í•¨ìˆ˜
def predict(path, model_path="svm_model.pkl"):
    try:
        scaler, classifier = load_model(model_path)
        processor, whisper_model, device = load_whisper_model()

        embedding = extract_embedding(path, processor, whisper_model, device)
        embedding_scaled = scaler.transform([embedding])

        prediction = classifier.predict(embedding_scaled)[0]
        if hasattr(classifier, "predict_proba"):
            probability = classifier.predict_proba(embedding_scaled)[0][prediction]  # í•´ë‹¹ í´ë˜ìŠ¤ì˜ í™•ë¥ 
        else:
            probability = classifier.decision_function(embedding_scaled)[0]  # fallback
        
        logging.info(f"ì˜ˆì¸¡ ì™„ë£Œ - ê²°ê³¼: {prediction}, í™•ë¥ : {probability:.4f}")
        
        return prediction, probability
    except Exception as e:
        logging.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        raise

def main():
    import argparse

    parser = argparse.ArgumentParser(description="Whisper ê¸°ë°˜ ìŒì„± ë¶„ë¥˜ê¸°")
    parser.add_argument("audio_path", type=str, help="ë¶„ì„í•  .wav ë˜ëŠ” .pcm íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model_path", type=str, default="svm_model.pkl", help="SVM ëª¨ë¸ pkl íŒŒì¼ ê²½ë¡œ")

    args = parser.parse_args()

    try:
        prediction, probability = predict(args.audio_path, args.model_path)
        print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: {prediction}, í™•ë¥  ì ìˆ˜: {probability:.4f}")
    except Exception as e:
        print(f"âš ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()
